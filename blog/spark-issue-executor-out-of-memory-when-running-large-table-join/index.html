<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Spark Issue: Executor Out of Memory When Running Large Table Join</title>
  <meta name="author" content="Ben Chuanlong Du">

  <link href="http://www.legendu.net/misc/atom.xml" type="application/atom+xml" rel="alternate"
        title="Ben Chuanlong Du's Blog Atom Feed" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="http://www.legendu.net/misc/favicon.png" rel="icon">
  <link href="http://www.legendu.net/misc/theme/css/main_2.css" media="screen, projection"
        rel="stylesheet" type="text/css">
  <script src="http://www.legendu.net/misc/theme/js/modernizr-2.0.js"></script>
  <script src="http://www.legendu.net/misc/theme/js/ender.js"></script>
  <script src="http://www.legendu.net/misc/theme/js/octopress.js" type="text/javascript"></script>

  <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="http://www.legendu.net/misc/">Ben Chuanlong Du's Blog</a></h1>
    <h2>It is never too late to learn.</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://www.legendu.net/misc/atom.xml" rel="subscribe-rss">RSS</a></li>
</ul>

<form name="search" action="https://www.bing.com/search" method="get" onSubmit="return build_query()">
  <fieldset role="search">
      <!--
    <input type="hidden" name="q" value="site:http://www.legendu.net/misc" />
        -->
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

<script type = "text/javascript">
    function build_query() {
        var query = document.forms["search"]["q"].value;
        var prefix = "site:http://www.legendu.net/misc "
        if (!query.startsWith(prefix)) {
            query = prefix + query;
            document.forms["search"]["q"].value = query;
        }
        return true;
    }
</script>

<ul class="main-navigation">
    <li><a href="http://www.legendu.net">Home</a></li>
    <li><a href="http://www.legendu.net/misc">Blog</a></li>
    <li><a href="http://www.legendu.net/misc/archives.html">Archives</a></li>
    <li><a href="http://www.legendu.net/misc/pages/links.html">Links</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Spark Issue: Executor Out of Memory When Running Large Table Join</h1>
      <p class="meta"><time datetime="2019-05-11T02:50:52-07:00" pubdate>May 11, 2019</time></p>
</header>

  <div class="entry-content"><p><strong>
Things on this page are fragmentary and immature notes/thoughts of the author.
It is not meant to readers but rather for convenient reference of the author and future improvement.
</strong></p>
<h2 id="symptom">Symptom</h2>
<h3 id="symptom-1">Symptom 1</h3>
<p>16/04/22 04:27:18 WARN yarn.YarnAllocator: Container marked as failed: container_1459803563374_223497_02_000067 on host.
Exit status: 143. Diagnostics: Container [pid=30502,containerID=container_1459803563374_223497_02_000067] is running beyond physical memory limits. 
Current usage: 13.8 GB of 13.8 GB physical memory used; 14.6 GB of 28.9 GB virtual memory used. Killing container.
Dump of the process-tree for container_1459803563374_223497_02_000067 :
|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
|- 30502 18022 30502 30502 (bash) 0 0 22773760 347 /bin/bash -c LD_LIBRARY_PATH=/apache/hadoop/lib/native:/apache/hadoop/lib/native/Linux-amd64-64: 
/usr/java/latest/bin/java -server -XX:OnOutOfMemoryError='kill %p' 
-Xms12288m -Xmx12288m -Djava.io.tmpdir=/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/tmp 
'-Dspark.driver.port=35848' '-Dspark.ui.port=0' '-Dspark.akka.threads=32' 
-Dspark.yarn.app.container.log.dir=/hadoop/10/scratch/logs/application_1459803563374_223497/container_1459803563374_223497_02_000067 
-XX:MaxPermSize=256m org.apache.spark.executor.CoarseGrainedExecutorBackend 
--driver-url spark://CoarseGrainedScheduler@10.115.16.50:35848 --executor-id 33 
--cores 3 --app-id application_1459803563374_223497 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/<strong>app</strong>.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/hbase-client-0.98.0-EBAY-21.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/hbase-server-0.98.0-EBAY-21.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/datanucleus-api-jdo-3.2.6.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/datanucleus-core-3.2.10.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/datanucleus-rdbms-3.2.9.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/mysql-connector-java-5.1.33.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/spark-avro_2.11-2.0.1.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/spark-csv_2.11-1.3.0.jar 
--user-class-path file:/hadoop/6/scratch/local/usercache/dclong/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/commons-csv-1.2.jar 1&gt; 
/hadoop/10/scratch/logs/application_1459803563374_223497/container_1459803563374_223497_02_000067/stdout 2&gt; /hadoop/10/scratch/logs/application_1459803563374_223497/container_1459803563374_223497_02_000067/stderr
|- 30524 30502 30502 30502 (java) 23870 3795 15701848064 3605090 /usr/java/latest/bin/java -server -XX:OnOutOfMemoryError=kill %p -Xms12288m -Xmx12288m -Djava.io.tmpdir=/hadoop/6/scratch/local/usercache/b_pandaren_kwdm/appcache/application_1459803563374_223497/container_1459803563374_223497_02_000067/tmp -Dspark.driver.port=35848 -Dspark.ui.port=0 -Dspark.akka.threads=32 -Dspark.yarn.app.container.log.dir=/hadoop/10/scratch/logs/application_1459803563374_223497/container_1459803563374_223497_02_000067 -XX:MaxPermSize=256m org.apache.spark.executor.CoarseGrainedExecutorBackend 
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143</p>
<h2 id="symptom-2">Symptom 2</h2>
<p>16/04/23 23:12:20 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 46
16/04/23 23:12:31 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
16/04/23 23:12:31 ERROR shuffle.RetryingBlockFetcher: Exception while beginning fetch of 1 outstanding blocks
java.io.IOException: Failed to connect to 10.115.45.46:40458
        at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
        at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
        at org.apache.spark.network.netty.NettyBlockTransferService</p>
<div class="math">$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
        at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
        at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:120)
        at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:99)
        at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:89)
        at org.apache.spark.storage.BlockManager$$</div>
<p>anonfun<span class="math">\(doGetRemote\)</span>2.apply(BlockManager.scala:588)
        at org.apache.spark.storage.BlockManager</p>
<div class="math">$$anonfun$doGetRemote$2.apply(BlockManager.scala:585)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at org.apache.spark.storage.BlockManager.doGetRemote(BlockManager.scala:585)
        at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:578)
        at org.apache.spark.broadcast.TorrentBroadcast$$</div>
<p>anonfun<span class="math">\(org\)</span>apache<span class="math">\(spark\)</span>broadcast<span class="math">\(TorrentBroadcast<div class="math">$$readBlocks$1.org$apache$spark$broadcast$TorrentBroadcast$$</div>anonfun<div class="math">$$getRemote$1(TorrentBroadcast.scala:127)
        at org.apache.spark.broadcast.TorrentBroadcast$$</div>anonfun\)</span>org<span class="math">\(apache\)</span>spark<span class="math">\(broadcast\)</span>TorrentBroadcast</p>
<div class="math">$$readBlocks$1$$</div>
<p>anonfun<span class="math">\(1.apply(TorrentBroadcast.scala:137)
        at org.apache.spark.broadcast.TorrentBroadcast<div class="math">$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$</div>readBlocks\)</span>1</p>
<div class="math">$$anonfun$1.apply(TorrentBroadcast.scala:137)
        at scala.Option.orElse(Option.scala:289)
        at org.apache.spark.broadcast.TorrentBroadcast$$</div>
<p>anonfun<span class="math">\(org\)</span>apache<span class="math">\(spark\)</span>broadcast<span class="math">\(TorrentBroadcast<div class="math">$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
        at org.apache.spark.broadcast.TorrentBroadcast$$</div>anonfun\)</span>org<span class="math">\(apache\)</span>spark<span class="math">\(broadcast\)</span>TorrentBroadcast</p>
<div class="math">$$readBlocks$1.apply(TorrentBroadcast.scala:120)
        at org.apache.spark.broadcast.TorrentBroadcast$$</div>
<p>anonfun<span class="math">\(org\)</span>apache<span class="math">\(spark\)</span>broadcast<span class="math">\(TorrentBroadcast<div class="math">$$readBlocks$1.apply(TorrentBroadcast.scala:120)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$</div>readBlocks(TorrentBroadcast.scala:120)
        at org.apache.spark.broadcast.TorrentBroadcast<div class="math">$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
        at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1219)
        at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
        at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
        at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
        at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
        at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: 10.115.45.46:40458
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
        at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
        ... 1 more
16/04/23 23:12:31 ERROR shuffle.RetryingBlockFetcher: Exception while beginning fetch of 3 outstanding blocks
java.lang.NullPointerException: group
        at io.netty.bootstrap.AbstractBootstrap.group(AbstractBootstrap.java:80)
        at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:189)
        at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
        at org.apache.spark.network.netty.NettyBlockTransferService$$</div>anon\)</span>1.createAndStart(NettyBlockTransferService.scala:90)
        at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
        at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:120)
        at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:99)
        at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:152)
        at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:316)
        at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:296)
        at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
        at scala.collection.Iterator</p>
<div class="math">$$anon$11.next(Iterator.scala:370)
        at scala.collection.Iterator$$</div>
<p>anon<span class="math">\(12.hasNext(Iterator.scala:396)
        at scala.collection.Iterator<div class="math">$$anon$11.hasNext(Iterator.scala:369)
        at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
        at scala.collection.Iterator$$</div>anon\)</span>11.hasNext(Iterator.scala:369)
        at org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:167)
        at org.apache.spark.sql.execution.Sort</p>
<div class="math">$$anonfun$1.apply(Sort.scala:90)
        at org.apache.spark.sql.execution.Sort$$</div>
<p>anonfun<span class="math">\(1.apply(Sort.scala:64)
        at org.apache.spark.rdd.RDD<div class="math">$$anonfun$mapPartitionsInternal$1$$</div>anonfun\)</span>apply<span class="math">\(21.apply(RDD.scala:728)
        at org.apache.spark.rdd.RDD<div class="math">$$anonfun$mapPartitionsInternal$1$$</div>anonfun\)</span>apply<span class="math">\(21.apply(RDD.scala:728)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor\)</span>TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
16/04/23 23:12:31 INFO shuffle.RetryingBlockFetcher: Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms</p>
<h2 id="cause">Cause</h2>
<ol>
<li>
<p>The buffer between the JVM heap size and the amount of memory requested from YARN is too small.</p>
</li>
<li>
<p>The netty transfer service will use off-heap buffers (whereas the NIO service doesn't).</p>
</li>
</ol>
<p>Note: this issue will only happen when some table size is larger than 50GB.</p>
<h2 id="solution">Solution</h2>
<p>The current state of the art is to increase 
One way is to increase <code>spark.yarn.executor.memoryOverhead</code> until the job stops failing. </p>
<div class="highlight"><pre><span></span><span class="c1">--conf spark.yarn.executor.memoryOverhead=2048M</span>
</pre></div>


<h2 id="references">References</h2>
<p>http://stackoverflow.com/questions/29850784/what-are-the-likely-causes-of-org-apache-spark-shuffle-metadatafetchfailedexcept </p>
<p>http://apache-spark-developers-list.1001551.n3.nabble.com/Lost-executor-on-YARN-ALS-iterations-td7916.html </p>
<p>https://issues.apache.org/jira/browse/SPARK-4516?focusedCommentId=14220157&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14220157</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' }, Macros: {} }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Benjamin Du</span>
  </span>
<time datetime="2019-05-11T02:50:52-07:00" pubdate>May 11, 2019</time>  <span class="categories">
    <a class="category" href="http://www.legendu.net/misc/tag/programming.html">programming</a>
    <a class="category" href="http://www.legendu.net/misc/tag/spark.html">Spark</a>
    <a class="category" href="http://www.legendu.net/misc/tag/issue.html">issue</a>
    <a class="category" href="http://www.legendu.net/misc/tag/big-data.html">big data</a>
  </span>
</p>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="http://www.legendu.net/misc/blog/python-tips/">Tips on Python</a>
      </li>
      <li class="post">
          <a href="http://www.legendu.net/misc/blog/python-tips-and-traps/">Python Tips and Traps</a>
      </li>
      <li class="post">
          <a href="http://www.legendu.net/misc/blog/exception-and-error-handling-in-python/">Exception and Error Handling in Python</a>
      </li>
      <li class="post">
          <a href="http://www.legendu.net/misc/blog/ipython-tips/">Tips on IPython</a>
      </li>
      <li class="post">
          <a href="http://www.legendu.net/misc/blog/tips-for-git-large-file-storage/">Tips for Git Large File Storage</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="http://www.legendu.net/misc/category/ai.html">AI</a></li>
        <li><a href="http://www.legendu.net/misc/category/career.html">Career</a></li>
        <li><a href="http://www.legendu.net/misc/category/cloud.html">Cloud</a></li>
        <li><a href="http://www.legendu.net/misc/category/database.html">Database</a></li>
        <li><a href="http://www.legendu.net/misc/category/encryption.html">Encryption</a></li>
        <li><a href="http://www.legendu.net/misc/category/english.html">English</a></li>
        <li><a href="http://www.legendu.net/misc/category/finance.html">Finance</a></li>
        <li><a href="http://www.legendu.net/misc/category/fun-problems.html">Fun Problems</a></li>
        <li><a href="http://www.legendu.net/misc/category/hardware.html">Hardware</a></li>
        <li><a href="http://www.legendu.net/misc/category/internet.html">Internet</a></li>
        <li><a href="http://www.legendu.net/misc/category/job.html">Job</a></li>
        <li><a href="http://www.legendu.net/misc/category/jupyterlab.html">JupyterLab</a></li>
        <li><a href="http://www.legendu.net/misc/category/language.html">Language</a></li>
        <li><a href="http://www.legendu.net/misc/category/life.html">Life</a></li>
        <li><a href="http://www.legendu.net/misc/category/links.html">Links</a></li>
        <li><a href="http://www.legendu.net/misc/category/linux.html">Linux</a></li>
        <li><a href="http://www.legendu.net/misc/category/machine-learning.html">Machine Learning</a></li>
        <li><a href="http://www.legendu.net/misc/category/macos.html">macOS</a></li>
        <li><a href="http://www.legendu.net/misc/category/network.html">Network</a></li>
        <li><a href="http://www.legendu.net/misc/category/os.html">OS</a></li>
        <li><a href="http://www.legendu.net/misc/category/people.html">People</a></li>
        <li><a href="http://www.legendu.net/misc/category/philosophy.html">Philosophy</a></li>
        <li><a href="http://www.legendu.net/misc/category/programming.html">Programming</a></li>
        <li><a href="http://www.legendu.net/misc/category/research.html">Research</a></li>
        <li><a href="http://www.legendu.net/misc/category/sheng-huo.html">生活</a></li>
        <li><a href="http://www.legendu.net/misc/category/si-suo.html">思索</a></li>
        <li><a href="http://www.legendu.net/misc/category/software.html">Software</a></li>
        <li><a href="http://www.legendu.net/misc/category/statistics.html">Statistics</a></li>
        <li><a href="http://www.legendu.net/misc/category/teleconference.html">Teleconference</a></li>
        <li><a href="http://www.legendu.net/misc/category/tools.html">Tools</a></li>
        <li><a href="http://www.legendu.net/misc/category/trading.html">Trading</a></li>
        <li><a href="http://www.legendu.net/misc/category/unix.html">Unix</a></li>
        <li><a href="http://www.legendu.net/misc/category/visualization.html">Visualization</a></li>
        <li><a href="http://www.legendu.net/misc/category/windows.html">Windows</a></li>
        <li><a href="http://www.legendu.net/misc/category/work.html">Work</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  <p class="tagcloud">
  </p>
  </section>



  <section>
    <h1>GitHub Repos</h1>
    <ul id="gh_repos">
      <li class="loading">Status updating...</li>
    </ul>
      <a href="https://github.com/dclong">@dclong</a> on GitHub
    <script type="text/javascript">
      $.domReady(function(){
          if (!window.jXHR){
              var jxhr = document.createElement('script');
              jxhr.type = 'text/javascript';
              jxhr.src = 'http://www.legendu.net/misc/theme/js/jXHR.js';
              var s = document.getElementsByTagName('script')[0];
              s.parentNode.insertBefore(jxhr, s);
          }

          github.showRepos({
              user: 'dclong',
              count: 3,
              skip_forks: true,
              target: '#gh_repos'
          });
      });
    </script>
    <script src="http://www.legendu.net/misc/theme/js/github.js" type="text/javascript"> </script>
  </section>

    <section>
        <h1>Social</h2>
        <ul>
            <li><a href="https://www.linkedin.com/in/ben-chuanlong-du-1239b221/" target="_blank">LinkedIn</a></li>
            <li><a href="https://twitter.com/longendu" target="_blank">Twitter</a></li>
            <li><a href="https://www.facebook.com/chuanlong.du" target="_blank">Facebook</a></li>
        <!--
            <li><a href="http://www.legendu.net/misc/" type="application/rss+xml" rel="alternate">RSS</a></li>
            -->
        </ul>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Ben Chuanlong Du -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-30259661-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
	<script type="text/javascript">
	  var disqus_shortname = 'dclong';
          var disqus_identifier = '/blog/spark-issue-executor-out-of-memory-when-running-large-table-join/';
          var disqus_url = 'http://www.legendu.net/misc/blog/spark-issue-executor-out-of-memory-when-running-large-table-join/';
          var disqus_title = 'Spark Issue: Executor Out of Memory When Running Large Table Join';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
</body>
</html>