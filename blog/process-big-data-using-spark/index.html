<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Process Big Data Using Spark</title>
  <meta name="author" content="Ben Chuanlong Du">

  <link href="https://misc.legendu.net/atom.xml" type="application/atom+xml" rel="alternate"
        title="Ben Chuanlong Du's Blog Atom Feed" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://misc.legendu.net/favicon.png" rel="icon">
  <link href="https://misc.legendu.net/theme/css/main_2.css" media="screen, projection"
        rel="stylesheet" type="text/css">
  <script src="https://misc.legendu.net/theme/js/modernizr-2.0.js"></script>
  <script src="https://misc.legendu.net/theme/js/ender.js"></script>
  <script src="https://misc.legendu.net/theme/js/octopress.js" type="text/javascript"></script>

  <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <script data-ad-client="ca-pub-3836424032203369" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://misc.legendu.net/">Ben Chuanlong Du's Blog</a></h1>
    <h2>It is never too late to learn.</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://misc.legendu.net/atom.xml" rel="subscribe-rss">RSS</a></li>
</ul>

<form name="search" action="https://www.bing.com/search" method="get" onSubmit="return build_query()">
  <fieldset role="search">
      <!--
    <input type="hidden" name="q" value="site:https://misc.legendu.net" />
        -->
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

<script type = "text/javascript">
    function build_query() {
        var query = document.forms["search"]["q"].value;
        var prefix = "site:https://misc.legendu.net "
        if (!query.startsWith(prefix)) {
            query = prefix + query;
            document.forms["search"]["q"].value = query;
        }
        return true;
    }
</script>

<ul class="main-navigation">
    <li><a href="https://www.legendu.net">Home</a></li>
    <li><a href="https://misc.legendu.net">Blog</a></li>
    <li><a href="https://misc.legendu.net/archives.html">Archives</a></li>
    <li><a href="https://misc.legendu.net/categories.html">Categories</a></li>
    <li><a href="https://misc.legendu.net/tags.html">Tags</a></li>
    <li><a href="https://www.legendu.net/pages/about">About</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Process Big Data Using Spark</h1>
      <p class="meta"><time datetime="2017-01-05T23:55:46-08:00" pubdate>Jan 05, 2017</time></p>
</header>

  <div class="entry-content"><p><strong>Things on this page are fragmentary and immature notes/thoughts of the author. Please read with your own judgement!</strong></p>
<h2 id="general-tips">General Tips</h2>
<ol>
<li>
<p>Please refer to 
    <a href="http://www.legendu.net/misc/blog/spark-sql-tips/">Spark SQL</a>
    for tips specific to Spark SQL.</p>
</li>
<li>
<p>It is almost always a good idea to filter out null value in the joinining columns before joining
    no matter it is an inner join or an outer join 
    (of course if the rows containing null matters in your use case, you have to do a union of those records).
    Spark (at least in Spark 2.3 and older) is stupid enough not to filter out joining keys/columns with null values before even INNER join
    (even if null values are dropped after inner join).
    This means that if a joining key/column has lots of null values, 
    it get shuffle into the same node in SortMergeJoin.
    This can cause a serious data skew issue.</p>
</li>
<li>
<p>When you join 2 tables and apply filtering conditions on those 2 tables, 
    it is suggested that you explictly use subqueries to filtering first and then do the join.
    (This is generally true for other SQL databases too.)</p>
<ul>
<li>
<p>Explict is always better than implicit. 
    This makes sure that SQL do the filtering first before join
    rather than relying on the SQL engine optimization.</p>
</li>
<li>
<p>This makes things easier if you need to leverage Spark SQL hints.</p>
</li>
</ul>
</li>
<li>
<p>It is always a good idea to check the execution plan of your Spark job 
    to make sure that things are as expected
    before you actually run it.</p>
</li>
<li>
<p>Before you use a HDFS table, 
    have a rough estimation of the tables size 
    and check the number of underlying files of the talbe.
    This helps you
        - have a rough idea of the complexity of the Spark job
        - get a idea of the rough number of tasks in the Spark job
        - decide the best number of shuffle partitions to use
    Notice that due to bad design,
    some HDFS table might have a huge number (more than 100k) of underlying files.
    This will causes your Spark job to have too many (small) tasks,
    which not only makes your Spark application run slow 
    but also might causes vairous issues such as 
    <a href="http://www.legendu.net/misc/blog/spark-issues-total-size-bigger-than-maxresultsize/">Spark Issue: Total Size of Serialized Results Is Bigger than spark.driver.maxResultSize</a>
    and
    <a href="http://www.legendu.net/misc/blog/spark-issue-too-large-table-for-auto-BroadcastHashJoin/">Spark Issue: Too Large Table for Auto BroadcastHashJoin</a>
    .</p>
</li>
<li>
<p>When you select columns from a table (or from joining of multiple tables),
    it is always a good idea to include partition/bucket columns in the final output.</p>
</li>
<li>
<p>If you have a really large Spark job which fails with high chance due too large complexity,
    you can check whether there are independent sub jobs in the big job.
    If so,
    it is often a good idea to submit separate Spark applications for each independent sub jobs.
    One typical example is when you do a large simulation. 
    Each iterator in the simulation can be seen as an independent job (of other iterators).
    If the whole simulation is too large and fails with high chance,
    you can break down the simulation into smaller piece.
    One useful trick is to use hash and/or modulus to help you cut the large job into smaller and reproducible ones. 
    You can then submit a Spark application for each of the smaller jobs.
    The advantage of this approach is 2 fold.
    First, 
    each of the smaller jobs can run reliably and have a much higher chance to suceed. 
    Second, 
    shall any of the smaller jobs fail, 
    you run rerun that specific job (this is why reproducible is important) instead of rerunning the whole large simulation.</p>
</li>
<li>
<p>It is suggested that you always call <code>spark.stop()</code> 
    when the SparkContext object is no longer needed (typically at the end of your Spark/PySpark application).
    This helps reduce the weird issue that all your output is written to the cluster successfully 
    but your Spark applications fails.
    For more discussions, 
    please refer to http://apache-spark-user-list.1001560.n3.nabble.com/SparkContext-stop-td17826.html.</p>
</li>
</ol>
<h2 id="sharing-variables">Sharing Variables</h2>
<p>Spark supports two types of shared variables: broadcast variables,
which can be used to cache a value in memory on all nodes,
and accumulators,
which are variables that are only “added” to, such as counters and sums.</p>
<h2 id="spark-submit">Spark Submit</h2>
<ol>
<li>
<p>All the options <code>--files</code>, <code>--jars</code> and <code>--archives</code> 
    support both local files and remote files on HDFS. </p>
</li>
<li>
<p>After submitting a Spark application, 
    if the network connection get lots, 
    the Spark application submitted will be killed.
    You can nohup or tmux to submit your Spark application 
    so that loss of network connection won't kill your Spark application.
    Or another way is to just submit your Spark application
    from a server that has very stable network connection.</p>
</li>
<li>
<p>Best to use the JVM option <code>-XX:MaxDirectMemorySize</code> to limit the maximum directory memory used.
    This helps avoid the issue of memory exceding limit.</p>
<div class="highlight"><pre><span></span><code>--conf<span class="w"> </span>spark.executor.extraJavaOptions<span class="o">=</span>-XX:MaxDirectMemorySize<span class="o">=</span>8G<span class="w"> </span><span class="se">\</span>
</code></pre></div>

</li>
<li>
<p>If you are sure that your Spark application is production ready,
    it is better to submit it with the option <code>--deploy-mode cluster</code>.
    However the default option (<code>--deploy-mode client</code>) is good for debugging.
    And also, <code>--deploy-mode client</code> is much faster to submit generally speaking.
    It is suggested that you use <code>--deploy-mode client</code> for ad hoc Spark applications
    and <code>--deploy-mode cluster</code> for production ready applications that need to be run many times.</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
/apache/spark2.3/bin/spark-submit<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--files<span class="w"> </span><span class="s2">&quot;file:///apache/hive/conf/hive-site.xml,file:///apache/hadoop/etc/hadoop/ssl-client.xml,file:///apache/hadoop/etc/hadoop/hdfs-site.xml,file:///apache/hadoop/etc/hadoop/core-site.xml,file:///apache/hadoop/etc/hadoop/federation-mapping.xml&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--master<span class="w"> </span>yarn<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--queue<span class="w"> </span>your_queue<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-executors<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-memory<span class="w"> </span>10G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--driver-memory<span class="w"> </span>15G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-cores<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.dynamicAllocation.enabled<span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.dynamicAllocation.maxExecutors<span class="o">=</span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.network.timeout<span class="o">=</span>300s<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.executor.memoryOverhead<span class="o">=</span>2G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.executor.extraJavaOptions<span class="o">=</span>-XX:MaxDirectMemorySize<span class="o">=</span>8G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--class<span class="w"> </span>your.package.SomeClass<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--jars<span class="w"> </span>/path/to/jar/dependencies<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>/path/to/compiled/jar<span class="w"> </span>arg1<span class="w"> </span>arg2<span class="w"> </span>...
</code></pre></div>

<p>If you have used Kotlin in your Spark application,
you need to include <code>kotlin-stdlib.jar</code> via the <code>--jars</code> option.</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
/apache/spark2.3/bin/spark-submit<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--files<span class="w"> </span><span class="s2">&quot;file:///apache/hive/conf/hive-site.xml,file:///apache/hadoop/etc/hadoop/ssl-client.xml,file:///apache/hadoop/etc/hadoop/hdfs-site.xml,file:///apache/hadoop/etc/hadoop/core-site.xml,file:///apache/hadoop/etc/hadoop/federation-mapping.xml&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--master<span class="w"> </span>yarn<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--queue<span class="w"> </span>your_queue<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-executors<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-memory<span class="w"> </span>10G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--driver-memory<span class="w"> </span>15G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-cores<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.dynamicAllocation.enabled<span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.dynamicAllocation.maxExecutors<span class="o">=</span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.network.timeout<span class="o">=</span>300s<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.executor.memoryOverhead<span class="o">=</span>2G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.executor.extraJavaOptions<span class="o">=</span>-XX:MaxDirectMemorySize<span class="o">=</span>8G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--class<span class="w"> </span>your.package.SomeClass<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--jars<span class="w"> </span>/path/to/kotlin-stdlib.jar<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>/path/to/compiled/jar<span class="w"> </span>arg1<span class="w"> </span>arg2<span class="w"> </span>...
</code></pre></div>

</li>
</ol>
<h2 id="spark-shell">Spark Shell</h2>
<ol>
<li>
<p>The <code>--jars</code> option of <code>spark-shell</code> can be used to add JAR dependencies.</p>
</li>
<li>
<p><code>spark-shell</code> accepts <code>--queue</code> (for specifying the queue to submit jobs) as parameter!
If you run <code>spark-shell</code> and encounter the issue of "ERROR SparkContext: Error initializing SparkContext" 
due to "application submitted by user to unknown queue",
you have to pass the queue that you can access to <code>spark-shell</code>.</p>
<div class="highlight"><pre><span></span><code>spark-shell<span class="w"> </span>--queue<span class="w"> </span>my_queue
</code></pre></div>

</li>
</ol>
<h2 id="spark-cluster-master-url">Spark Cluster Master URL</h2>
<p>https://spark.apache.org/docs/latest/submitting-applications.html#master-urls</p>
<h2 id="references">References</h2>
<p><a href="https://github.com/awesome-spark/awesome-spark">awesome-spark</a></p>
<p>https://developer.ibm.com/hadoop/2016/07/18/troubleshooting-and-tuning-spark-for-heavy-workloads/</p>
<p>http://blog.prabeeshk.com/blog/2014/10/31/install-apache-spark-on-ubuntu-14-dot-04/</p>
<p>http://mbonaci.github.io/mbo-spark/</p>
<p>http://www.simonouellette.com/blog/spark-join-when-not-to-use-it</p>
<p>https://bzhangusc.wordpress.com/2015/11/20/use-sbt-console-as-spark-shell/</p>
<p>https://spark-summit.org/2015/events/interactive-graph-analytics-with-spark/</p>
<p>https://www.slideshare.net/SparkSummit/understanding-memory-management-in-spark-for-fun-and-profit</p>
<p>http://apache-spark-user-list.1001560.n3.nabble.com/SparkContext-stop-td17826.html</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Ben Chuanlong Du</span>
  </span>
<time datetime="2017-01-05T23:55:46-08:00" pubdate>Jan 05, 2017</time>  <span class="categories">
    <a class="category" href="https://misc.legendu.net/tag/programming.html">programming</a>
    <a class="category" href="https://misc.legendu.net/tag/spark.html">Spark</a>
    <a class="category" href="https://misc.legendu.net/tag/big-data.html">big data</a>
    <a class="category" href="https://misc.legendu.net/tag/tips.html">tips</a>
  </span>
</p>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-health/">Tips on Health</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-child-education/">Tips on Child Education</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-fd/">Tips on fd</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/the-fzf-command-is-a-great-alternative-to-find/">The fzf Command Is a Great Alternative to find</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/ruff-is-an-extremely-fast-python-linter-written-in-rust/">Ruff Is An Extremely Fast Python Linter Written in Rust</a>
      </li>
    </ul>
  </section>
  <section>
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://misc.legendu.net/category/ai.html">AI</a></li>
        <li><a href="https://misc.legendu.net/category/career.html">Career</a></li>
        <li><a href="https://misc.legendu.net/category/cloud.html">Cloud</a></li>
        <li><a href="https://misc.legendu.net/category/computer-science.html">Computer Science</a></li>
        <li><a href="https://misc.legendu.net/category/fiannce.html">Fiannce</a></li>
        <li><a href="https://misc.legendu.net/category/finance.html">Finance</a></li>
        <li><a href="https://misc.legendu.net/category/fun-problems.html">Fun Problems</a></li>
        <li><a href="https://misc.legendu.net/category/hardware.html">Hardware</a></li>
        <li><a href="https://misc.legendu.net/category/health.html">Health</a></li>
        <li><a href="https://misc.legendu.net/category/house.html">House</a></li>
        <li><a href="https://misc.legendu.net/category/internet.html">Internet</a></li>
        <li><a href="https://misc.legendu.net/category/investment.html">Investment</a></li>
        <li><a href="https://misc.legendu.net/category/life.html">life</a></li>
        <li><a href="https://misc.legendu.net/category/linux.html">Linux</a></li>
        <li><a href="https://misc.legendu.net/category/os.html">OS</a></li>
        <li><a href="https://misc.legendu.net/category/people.html">People</a></li>
        <li><a href="https://misc.legendu.net/category/philosophy.html">Philosophy</a></li>
        <li><a href="https://misc.legendu.net/category/research.html">Research</a></li>
        <li><a href="https://misc.legendu.net/category/shopping.html">Shopping</a></li>
        <li><a href="https://misc.legendu.net/category/soft-skills.html">soft skills</a></li>
        <li><a href="https://misc.legendu.net/category/software.html">Software</a></li>
        <li><a href="https://misc.legendu.net/category/statistics.html">Statistics</a></li>
        <li><a href="https://misc.legendu.net/category/tools.html">Tools</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  <ul class="tagcloud">
  </ul>
  </section>



  <section>
    <h1>GitHub Repos</h1>
    <ul id="gh_repos">
      <li class="loading">Status updating...</li>
    </ul>
      <a href="https://github.com/legendu-net">@legendu-net</a> on GitHub
    <script type="text/javascript">
      $.domReady(function(){
          if (!window.jXHR){
              var jxhr = document.createElement('script');
              jxhr.type = 'text/javascript';
              jxhr.src = 'https://misc.legendu.net/theme/js/jXHR.js';
              var s = document.getElementsByTagName('script')[0];
              s.parentNode.insertBefore(jxhr, s);
          }

          github.showRepos({
              user: 'legendu-net',
              count: 5,
              skip_forks: true,
              target: '#gh_repos'
          });
      });
    </script>
    <script src="https://misc.legendu.net/theme/js/github.js" type="text/javascript"> </script>
  </section>

    <section>
        <h1>Social</h2>
        <ul>
            <li><a href="https://www.linkedin.com/in/ben-chuanlong-du-1239b221/" target="_blank">LinkedIn</a></li>
            <li><a href="https://hub.docker.com/u/dclong" target="_blank">Docker Hub</a></li>
            <li><a href="https://stackoverflow.com/users/7808204/benjamin-du?tab=profile" target="_blank">Stack Overflow</a></li>
            <li><a href="https://twitter.com/longendu" target="_blank">Twitter</a></li>
        <!--
            <li><a href="https://misc.legendu.net/" type="application/rss+xml" rel="alternate">RSS</a></li>
            -->
        </ul>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Ben Chuanlong Du -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3STS9BVPF6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3STS9BVPF6');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'dclong';
          var disqus_identifier = '/blog/process-big-data-using-spark/';
          var disqus_url = 'https://misc.legendu.net/blog/process-big-data-using-spark/';
          var disqus_title = 'Process Big Data Using Spark';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
</body>
</html>