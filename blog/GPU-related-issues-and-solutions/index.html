<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>GPU Related Issues and Solutions</title>
  <meta name="author" content="Ben Chuanlong Du">

  <link href="https://misc.legendu.net/atom.xml" type="application/atom+xml" rel="alternate"
        title="Ben Chuanlong Du's Blog Atom Feed" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://misc.legendu.net/favicon.png" rel="icon">
  <link href="https://misc.legendu.net/theme/css/main_2.css" media="screen, projection"
        rel="stylesheet" type="text/css">
  <script src="https://misc.legendu.net/theme/js/modernizr-2.0.js"></script>
  <script src="https://misc.legendu.net/theme/js/ender.js"></script>
  <script src="https://misc.legendu.net/theme/js/octopress.js" type="text/javascript"></script>

  <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <script data-ad-client="ca-pub-3836424032203369" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://misc.legendu.net/">Ben Chuanlong Du's Blog</a></h1>
    <h2>It is never too late to learn.</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://misc.legendu.net/atom.xml" rel="subscribe-rss">RSS</a></li>
</ul>

<form name="search" action="https://www.bing.com/search" method="get" onSubmit="return build_query()">
  <fieldset role="search">
      <!--
    <input type="hidden" name="q" value="site:https://misc.legendu.net" />
        -->
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

<script type = "text/javascript">
    function build_query() {
        var query = document.forms["search"]["q"].value;
        var prefix = "site:https://misc.legendu.net "
        if (!query.startsWith(prefix)) {
            query = prefix + query;
            document.forms["search"]["q"].value = query;
        }
        return true;
    }
</script>

<ul class="main-navigation">
    <li><a href="https://www.legendu.net">Home</a></li>
    <li><a href="https://misc.legendu.net">Blog</a></li>
    <li><a href="https://misc.legendu.net/archives.html">Archives</a></li>
    <li><a href="https://misc.legendu.net/categories.html">Categories</a></li>
    <li><a href="https://misc.legendu.net/tags.html">Tags</a></li>
    <li><a href="https://www.legendu.net/pages/about">About</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">GPU Related Issues and Solutions</h1>
      <p class="meta"><time datetime="2020-01-03T09:22:43-08:00" pubdate>Jan 03, 2020</time></p>
</header>

  <div class="entry-content"><p><strong>Things on this page are fragmentary and immature notes/thoughts of the author. Please read with your own judgement!</strong></p>
<h2 id="tips">Tips</h2>
<ol>
<li>
<p>Training a model requires significantly more CPU/GPU memories than running inference using the model. </p>
</li>
<li>
<p>torch.cuda.empty_cache() doesn't help if memory is not enough </p>
</li>
<li>
<p>It is suggested that you train deep learning models on Linux 
(even if you can also do it on Windows).</p>
</li>
<li>
<p>If neural network's performance is not improving during training,
you can try increasing batch size or reduce learning rate.</p>
</li>
<li>
<p>8G GPU memory is too small for training large deep learning models. </p>
</li>
</ol>
<p>Trade compute for memory using
TORCH.UTILS.CHECKPOINT
https://pytorch.org/docs/stable/checkpoint.html</p>
<ol>
<li>The consumption of GPU memory has an approximately linear relationship with the batch size used for training. </li>
</ol>
<h2 id="batch-norm-layers">Batch Norm Layers</h2>
<p>The momentum parameter can be tuned to 
make the running estimates more smoothed.</p>
<h2 id="gpu-memory">GPU Memory</h2>
<p>The displayed memory usage by using <code>nvidia-smi</code> includes the CUDA context + the actual memory used to store tensors + cached memory + other applications.
To get more accurate memory usage by PyTorch,
Try to check the memory using torch.cuda.memory_allocated() and torch.cuda.memory_cached().</p>
<p>You could use <a href="https://pytorch.org/docs/stable/amp.html">Automatic Mixed Precision</a> to use float16, where applicable.</p>
<p>You could use a smaller batch size and accumulate the gradients. 
Then after a few iterations you could update the parameters using your optimizer.
It would yield the same behavior regarding the gradients, 
but note that other layers like BatchNorm will behave differently, 
since they see smaller batches.
If thatâ€™s problematic, e.g. when your batch size is really small, 
then you could change the momentum a bit or use other normalization layers, 
e.g. GroupNorm which should be more stable regarding smaller batch sizes.
For more discussions,
please refer to 
<a href="https://discuss.pytorch.org/t/why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch/4903">Why do we need to set the gradients manually to zero in pytorch?</a></p>
<h2 id="a-large-portion-of-gpu-memory-is-already-used">A Large Portion of GPU Memory is Already Used</h2>
<p>If you train models using GPU on your own desktop computer
(no matter Linux or Windows),
you might notice that even before you do anything with model training,
there's already a large portion of GPU memory used by other applications
(check it using <code>nvidia-smi</code>).
It is suggested that you take the following actions to free GPU memories 
before training your models.</p>
<ol>
<li>
<p>Close non-needed applications (especially those apps which uses GPU).</p>
</li>
<li>
<p>Switch to TTY (using the shortcut Ctrl + Shift + F1, F2, etc.) if you are using Linux,
    which can already help free most used GPU memories.</p>
</li>
<li>
<p>Boot your Linux machine into text model if you absolutely want squeeze all GPU memory 
    out of other applications (mostly X11).</p>
</li>
</ol>
<h2 id="cuda-out-of-memory">CUDA Out of Memory</h2>
<p>torch.cuda.memory_summary()</p>
<p><a href="https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch">How to avoid "CUDA out of memory" in PyTorch</a></p>
<ol>
<li>
<p>reduce training/testing batch size</p>
</li>
<li>
<p>clear PyTorch caches</p>
</li>
<li>
<p>add <code>torch.cuda.empty_cache()</code> before training each epoch</p>
</li>
<li>
<p>Free GPU memory from other applications (see the previous section)</p>
</li>
<li>
<p><a href="http://www.legendu.net/misc/blog/reduce-memory-needed-to-train-deep-learning-model">Reduce Memory Needed to Train Deep Learning Models</a></p>
</li>
</ol>
<p><a href="https://github.com/pytorch/pytorch/issues/35901">OOM error where ~50% of the GPU RAM cannot be utilised/reserved #35901</a></p>
<h2 id="ptxas-application-ptx-input-line-9-fatal-unsupported-version-65-current-version-is-64">ptxas application ptx input, line 9; fatal   : Unsupported .version 6.5; current version is '6.4'</h2>
<p>After installing cudatoolkit 10.2.89, 
I got the following error message when using the numba JIT feature.</p>
<blockquote>
<p>/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/decorators.py:111: UserWarning: autojit is deprecated and will be removed in a future release. Use jit instead.
  warn('autojit is deprecated and will be removed in a future release. Use jit instead.')
Traceback (most recent call last):
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py", line 1563, in add_ptx
    ptxbuf, len(ptx), namebuf, 0, None, None)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py", line 288, in safe_cuda_api_call
    self._check_error(fname, retcode)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py", line 323, in _check_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [218] Call to cuLinkAddData results in UNKNOWN_CUDA_ERROR</p>
<p>During handling of the above exception, another exception occurred:</p>
<p>Traceback (most recent call last):
  File "./test.py", line 28, in <module>
    func2(a)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/dispatcher.py", line 42, in <strong>call</strong>
    return self.compiled(<em>args, </em><em>kws)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/compiler.py", line 736, in <strong>call</strong>
    kernel = self.specialize(</em>args)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/compiler.py", line 747, in specialize
    kernel = self.compile(argtypes)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/compiler.py", line 765, in compile
    kernel.bind()
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/compiler.py", line 495, in bind
    self._func.get()
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/compiler.py", line 377, in get
    linker.add_ptx(ptx)
  File "/home/admin1/anaconda3/lib/python3.7/site-packages/numba/cuda/cudadrv/driver.py", line 1565, in add_ptx
    raise LinkerError("%s\n%s" % (e, self.error_log))
numba.cuda.cudadrv.driver.LinkerError: [218] Call to cuLinkAddData results in UNKNOWN_CUDA_ERROR
ptxas application ptx input, line 9; fatal   : Unsupported .version 6.5; current version is '6.4'
ptxas fatal   : Ptx assembly aborted due to errors</p>
</blockquote>
<p>Downgrading cudatoolkit to 10.1.243 fixed the issue.</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Benjamin Du</span>
  </span>
<time datetime="2020-01-03T09:22:43-08:00" pubdate>Jan 03, 2020</time>  <span class="categories">
    <a class="category" href="https://misc.legendu.net/tag/programming.html">programming</a>
    <a class="category" href="https://misc.legendu.net/tag/gpu.html">GPU</a>
    <a class="category" href="https://misc.legendu.net/tag/issues.html">issues</a>
    <a class="category" href="https://misc.legendu.net/tag/solutions.html">solutions</a>
  </span>
</p>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-health/">Tips on Health</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-child-education/">Tips on Child Education</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/tips-on-fd/">Tips on fd</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/the-fzf-command-is-a-great-alternative-to-find/">The fzf Command Is a Great Alternative to find</a>
      </li>
      <li class="post">
          <a href="https://misc.legendu.net/blog/ruff-is-an-extremely-fast-python-linter-written-in-rust/">Ruff Is An Extremely Fast Python Linter Written in Rust</a>
      </li>
    </ul>
  </section>
  <section>
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://misc.legendu.net/category/ai.html">AI</a></li>
        <li><a href="https://misc.legendu.net/category/career.html">Career</a></li>
        <li><a href="https://misc.legendu.net/category/cloud.html">Cloud</a></li>
        <li><a href="https://misc.legendu.net/category/computer-science.html">Computer Science</a></li>
        <li><a href="https://misc.legendu.net/category/fiannce.html">Fiannce</a></li>
        <li><a href="https://misc.legendu.net/category/finance.html">Finance</a></li>
        <li><a href="https://misc.legendu.net/category/fun-problems.html">Fun Problems</a></li>
        <li><a href="https://misc.legendu.net/category/hardware.html">Hardware</a></li>
        <li><a href="https://misc.legendu.net/category/health.html">Health</a></li>
        <li><a href="https://misc.legendu.net/category/house.html">House</a></li>
        <li><a href="https://misc.legendu.net/category/internet.html">Internet</a></li>
        <li><a href="https://misc.legendu.net/category/investment.html">Investment</a></li>
        <li><a href="https://misc.legendu.net/category/life.html">life</a></li>
        <li><a href="https://misc.legendu.net/category/linux.html">Linux</a></li>
        <li><a href="https://misc.legendu.net/category/os.html">OS</a></li>
        <li><a href="https://misc.legendu.net/category/people.html">People</a></li>
        <li><a href="https://misc.legendu.net/category/philosophy.html">Philosophy</a></li>
        <li><a href="https://misc.legendu.net/category/research.html">Research</a></li>
        <li><a href="https://misc.legendu.net/category/shopping.html">Shopping</a></li>
        <li><a href="https://misc.legendu.net/category/soft-skills.html">soft skills</a></li>
        <li><a href="https://misc.legendu.net/category/software.html">Software</a></li>
        <li><a href="https://misc.legendu.net/category/statistics.html">Statistics</a></li>
        <li><a href="https://misc.legendu.net/category/tools.html">Tools</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  <ul class="tagcloud">
  </ul>
  </section>



  <section>
    <h1>GitHub Repos</h1>
    <ul id="gh_repos">
      <li class="loading">Status updating...</li>
    </ul>
      <a href="https://github.com/legendu-net">@legendu-net</a> on GitHub
    <script type="text/javascript">
      $.domReady(function(){
          if (!window.jXHR){
              var jxhr = document.createElement('script');
              jxhr.type = 'text/javascript';
              jxhr.src = 'https://misc.legendu.net/theme/js/jXHR.js';
              var s = document.getElementsByTagName('script')[0];
              s.parentNode.insertBefore(jxhr, s);
          }

          github.showRepos({
              user: 'legendu-net',
              count: 5,
              skip_forks: true,
              target: '#gh_repos'
          });
      });
    </script>
    <script src="https://misc.legendu.net/theme/js/github.js" type="text/javascript"> </script>
  </section>

    <section>
        <h1>Social</h2>
        <ul>
            <li><a href="https://www.linkedin.com/in/ben-chuanlong-du-1239b221/" target="_blank">LinkedIn</a></li>
            <li><a href="https://hub.docker.com/u/dclong" target="_blank">Docker Hub</a></li>
            <li><a href="https://stackoverflow.com/users/7808204/benjamin-du?tab=profile" target="_blank">Stack Overflow</a></li>
            <li><a href="https://twitter.com/longendu" target="_blank">Twitter</a></li>
        <!--
            <li><a href="https://misc.legendu.net/" type="application/rss+xml" rel="alternate">RSS</a></li>
            -->
        </ul>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Ben Chuanlong Du -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3STS9BVPF6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3STS9BVPF6');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'dclong';
          var disqus_identifier = '/blog/GPU-related-issues-and-solutions/';
          var disqus_url = 'https://misc.legendu.net/blog/GPU-related-issues-and-solutions/';
          var disqus_title = 'GPU Related Issues and Solutions';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
</body>
</html>